{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing scikit learn functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in products dataframe: 183531\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "products = pd.read_csv('./data/amazon_baby.csv')\n",
    "print('No. of records in products dataframe: {}'.format(len(products.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      The First Years Massaging Action Teether\n",
       "review                    A favorite in our house!\n",
       "rating                                           5\n",
       "Name: 269, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.loc[269, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT . Make sure to fill n/a values in the review column with empty strings (if applicable). The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the review columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string    \n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "products['review'] = products.review.astype(str)\n",
    "products[\"review_without_punctuation\"] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'favorite': 1, 'in': 1, 'our': 1, 'house': 1}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(sentence):\n",
    "    word_count_dict = {}\n",
    "    for word in [aword.lower() for aword in sentence.split()]:\n",
    "        if word in word_count_dict.keys():\n",
    "            word_count_dict[word] = word_count_dict[word] + 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1\n",
    "    return word_count_dict\n",
    "\n",
    "products[\"word_count\"] = products[\"review_without_punctuation\"].apply(word_count)\n",
    "products.loc[269, :]['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166752"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_without_punctuation</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>{'it': 3, 'came': 1, 'early': 1, 'and': 3, 'wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>{'very': 1, 'soft': 1, 'and': 2, 'comfortable'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>{'this': 4, 'is': 4, 'a': 2, 'product': 2, 'we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>{'all': 2, 'of': 1, 'my': 1, 'kids': 2, 'have'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>{'when': 2, 'the': 6, 'binky': 3, 'fairy': 3, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                          review_without_punctuation  \\\n",
       "1  it came early and was not disappointed i love ...   \n",
       "2  Very soft and comfortable and warmer than it l...   \n",
       "3  This is a product well worth the purchase  I h...   \n",
       "4  All of my kids have cried nonstop when I tried...   \n",
       "5  When the Binky Fairy came to our house we didn...   \n",
       "\n",
       "                                          word_count  sentiment  \n",
       "1  {'it': 3, 'came': 1, 'early': 1, 'and': 3, 'wa...          1  \n",
       "2  {'very': 1, 'soft': 1, 'and': 2, 'comfortable'...          1  \n",
       "3  {'this': 4, 'is': 4, 'a': 2, 'product': 2, 'we...          1  \n",
       "4  {'all': 2, 'of': 1, 'my': 1, 'kids': 2, 'have'...          1  \n",
       "5  {'when': 2, 'the': 6, 'binky': 3, 'fairy': 3, ...          1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133401\n",
      "33351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(products, test_size=0.2, random_state=42)\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "train_y = train_data['sentiment']\n",
    "test_y = test_data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features . Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "1. Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "2. Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "3. Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix .\n",
    "4. Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "vectorizer.fit(train_data['review_without_punctuation'])\n",
    "# input feature matrix for training set\n",
    "train_X = vectorizer.transform(train_data['review_without_punctuation'])\n",
    "# input feature matrix for test set\n",
    "test_X = vectorizer.transform(test_data['review_without_punctuation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data.\n",
    "\n",
    "Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix ( train_X ) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\anupam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sentiment_model = LogisticRegression()\n",
    "sentiment_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.32054538e-01,  5.27842210e-04,  1.27606062e-02, ...,\n",
       "         7.06640848e-03,  5.00426878e-03, -9.97085646e-05]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model, we can extract the weights (coefficients) as an SFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of coefficients: 121841\n",
      "No of +ve coefficients: 85784\n",
      "No of -ve coefficients: 36057\n"
     ]
    }
   ],
   "source": [
    "def print_model_coeff(model):\n",
    "    coeffs = model.coef_\n",
    "    num_coeff = coeffs.shape[1]\n",
    "    print('No. of coefficients: {}'.format(num_coeff))\n",
    "    num_positive_coeff = [coeff for coeff in coeffs[0] if coeff > 0]\n",
    "    print('No of +ve coefficients: {}'.format(len(num_positive_coeff)))\n",
    "    print('No of -ve coefficients: {}'.format(num_coeff - len(num_positive_coeff)))\n",
    "    \n",
    "print_model_coeff(sentiment_model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `121713` coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** How many weights are >= 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80054    2\n",
      "44765    5\n",
      "48173    5\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_without_punctuation</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80054</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>I like the idea but the problems:-awkward clos...</td>\n",
       "      <td>2</td>\n",
       "      <td>I like the idea but the problemsawkward closin...</td>\n",
       "      <td>{'i': 1, 'like': 1, 'the': 13, 'idea': 1, 'but...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44765</th>\n",
       "      <td>Moby Wrap UV SPF 50+ 100% Cotton Baby Carrier,...</td>\n",
       "      <td>This is my 2nd Moby, just wanted another color...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is my 2nd Moby just wanted another color ...</td>\n",
       "      <td>{'this': 3, 'is': 4, 'my': 7, '2nd': 1, 'moby'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48173</th>\n",
       "      <td>The First Years American Red Cross Deluxe Nail...</td>\n",
       "      <td>This is the best nail clipper! Definitely reco...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the best nail clipper Definitely recom...</td>\n",
       "      <td>{'this': 2, 'is': 1, 'the': 3, 'best': 1, 'nai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "80054  Simple Wishes Hands-Free Breastpump Bra, Pink,...   \n",
       "44765  Moby Wrap UV SPF 50+ 100% Cotton Baby Carrier,...   \n",
       "48173  The First Years American Red Cross Deluxe Nail...   \n",
       "\n",
       "                                                  review  rating  \\\n",
       "80054  I like the idea but the problems:-awkward clos...       2   \n",
       "44765  This is my 2nd Moby, just wanted another color...       5   \n",
       "48173  This is the best nail clipper! Definitely reco...       5   \n",
       "\n",
       "                              review_without_punctuation  \\\n",
       "80054  I like the idea but the problemsawkward closin...   \n",
       "44765  This is my 2nd Moby just wanted another color ...   \n",
       "48173  This is the best nail clipper Definitely recom...   \n",
       "\n",
       "                                              word_count  sentiment  \n",
       "80054  {'i': 1, 'like': 1, 'the': 13, 'idea': 1, 'but...         -1  \n",
       "44765  {'this': 3, 'is': 4, 'my': 7, '2nd': 1, 'moby'...          1  \n",
       "48173  {'this': 2, 'is': 1, 'the': 3, 'best': 1, 'nai...          1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print(sample_test_data['rating'])\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I like the idea but the problems:-awkward closing! zipper requires two hands but you are likely to have the cups of the pump fall out or slip around while zipping-size range XS-medium?? got to be kidding. it's very picky trying to get the width of the back and front so that your nipples fall right in the center of the front nipple openings. and if they're off to the side the cups of the pump slide and nipples rub the insides during pumping-- OUCH!-not worth the price-not a bra I'd want to wear all day and getting it on and off also not convenient.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems negative.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (+1), the review is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is my 2nd Moby, just wanted another color to switch off with.  Thought it would be nice to keep one in the house and one in the car. However, just had to pass one of mine on to a friend who tried my moby out and loved it so much!  I guess I'll have to get yet another!  Moby wraps are excellent for your back and shoulders, and the child loves being close to mommy or whomever is wearing the wrap.  I even had my almost 3 year old daughter in it a couple weeks ago, although I use it most with my newborn, and will continue to as she grows.  This is my 3rd baby using Moby's with- I love them!  They are so comfortable and are simple to put on after following the instructions and doing it a few times.  I wear it going out sometimes, so it's convenient to just slip the baby in when I arrive at my destination.  Breathable cotton is great and it has a little bit of a stretch to it.  It's also nice to be able to face the baby outward once they can hold their heads up really well.  Mine have always loved to face outward once they are interested in looking around a little.  I would give a Moby to anyone as a gift.  To me it's basically a Must-have.  It's so comfortable and has a nice look to it too!  Also, I've done some skin-to-skin contact with my newborn this time and it worked so nice with wearing her in the Moby around the house some, and we're both covered up too. I would reccommend a Moby to anyone!\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[1]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the scores. For each row, the score (or margin) is a number in the range (-inf, inf). Use a pre-built function in your tool to calculate the score of each data point in sample_test_data . In scikit-learn, you can call the decision_function() function.\n",
    "\n",
    "Hint : You'd probably need to convert sample_test_data into the sparse matrix format first.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.54702071 17.02641369  4.88924495]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_without_punctuation'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate predicted labels for sample_test_data .\n",
    "\n",
    "Checkpoint : Make sure your class predictions match with the ones obtained from sentiment_model . The logistic regression classifier in scikit-learn comes with the predict function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  1]\n"
     ]
    }
   ],
   "source": [
    "predicted_sentiment = sentiment_model.predict(sample_test_matrix)\n",
    "print(predicted_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3665559  0.99999996 0.99252913]\n"
     ]
    }
   ],
   "source": [
    "probability_calculated = 1 / (1 + np.exp(-scores))\n",
    "print(probability_calculated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to sklearn:\n",
      "[0.3665559  0.99999996 0.99252913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_without_punctuation</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80054</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>I like the idea but the problems:-awkward clos...</td>\n",
       "      <td>2</td>\n",
       "      <td>I like the idea but the problemsawkward closin...</td>\n",
       "      <td>{'i': 1, 'like': 1, 'the': 13, 'idea': 1, 'but...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.366556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48173</th>\n",
       "      <td>The First Years American Red Cross Deluxe Nail...</td>\n",
       "      <td>This is the best nail clipper! Definitely reco...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the best nail clipper Definitely recom...</td>\n",
       "      <td>{'this': 2, 'is': 1, 'the': 3, 'best': 1, 'nai...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44765</th>\n",
       "      <td>Moby Wrap UV SPF 50+ 100% Cotton Baby Carrier,...</td>\n",
       "      <td>This is my 2nd Moby, just wanted another color...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is my 2nd Moby just wanted another color ...</td>\n",
       "      <td>{'this': 3, 'is': 4, 'my': 7, '2nd': 1, 'moby'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "80054  Simple Wishes Hands-Free Breastpump Bra, Pink,...   \n",
       "48173  The First Years American Red Cross Deluxe Nail...   \n",
       "44765  Moby Wrap UV SPF 50+ 100% Cotton Baby Carrier,...   \n",
       "\n",
       "                                                  review  rating  \\\n",
       "80054  I like the idea but the problems:-awkward clos...       2   \n",
       "48173  This is the best nail clipper! Definitely reco...       5   \n",
       "44765  This is my 2nd Moby, just wanted another color...       5   \n",
       "\n",
       "                              review_without_punctuation  \\\n",
       "80054  I like the idea but the problemsawkward closin...   \n",
       "48173  This is the best nail clipper Definitely recom...   \n",
       "44765  This is my 2nd Moby just wanted another color ...   \n",
       "\n",
       "                                              word_count  sentiment  \\\n",
       "80054  {'i': 1, 'like': 1, 'the': 13, 'idea': 1, 'but...         -1   \n",
       "48173  {'this': 2, 'is': 1, 'the': 3, 'best': 1, 'nai...          1   \n",
       "44765  {'this': 3, 'is': 4, 'my': 7, '2nd': 1, 'moby'...          1   \n",
       "\n",
       "       predicted_probab  \n",
       "80054          0.366556  \n",
       "48173          0.992529  \n",
       "44765          1.000000  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Class predictions according to sklearn:\" )\n",
    "predicted_probab = sentiment_model.predict_proba(sample_test_matrix)\n",
    "print(predicted_probab[:, 1])\n",
    "sample_test_data[\"predicted_probab\"] = predicted_probab[:, 1]\n",
    "sample_test_data.sort_values(by=['predicted_probab'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_data**, and use sklearn to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. \n",
    "2.  Sort the data according to those predictions and pick the top 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_without_punctuation</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59320</th>\n",
       "      <td>Evenflo Aura Select Travel System - Caroline</td>\n",
       "      <td>I'm about to be a first-time mom, so I spent w...</td>\n",
       "      <td>5</td>\n",
       "      <td>Im about to be a firsttime mom so I spent week...</td>\n",
       "      <td>{'im': 2, 'about': 3, 'to': 14, 'be': 4, 'a': ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142686</th>\n",
       "      <td>Thirsties Duo Diaper Snap, Mud, Size One (6-18...</td>\n",
       "      <td>I will try to keep this short.  Have tried man...</td>\n",
       "      <td>5</td>\n",
       "      <td>I will try to keep this short  Have tried many...</td>\n",
       "      <td>{'i': 18, 'will': 2, 'try': 1, 'to': 15, 'keep...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123632</th>\n",
       "      <td>Zooper 2011 Waltz Standard Stroller, Flax Brown</td>\n",
       "      <td>I did a TON of research before I purchased thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>I did a TON of research before I purchased thi...</td>\n",
       "      <td>{'i': 20, 'did': 1, 'a': 52, 'ton': 1, 'of': 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50735</th>\n",
       "      <td>Joovy Zoom 360 Swivel Wheel Jogging Stroller, ...</td>\n",
       "      <td>The joovy zoom 360 was the perfect solution fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>The joovy zoom 360 was the perfect solution fo...</td>\n",
       "      <td>{'the': 61, 'joovy': 1, 'zoom': 1, '360': 1, '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129722</th>\n",
       "      <td>Bumbleride 2011 Flite Lightweight Compact Trav...</td>\n",
       "      <td>This is a review of the 2012 Bumbleride Flite ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a review of the 2012 Bumbleride Flite ...</td>\n",
       "      <td>{'this': 12, 'is': 23, 'a': 38, 'review': 2, '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100166</th>\n",
       "      <td>Infantino Wrap and Tie Baby Carrier, Black Blu...</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>{'i': 28, 'bought': 1, 'this': 6, 'carrier': 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168086</th>\n",
       "      <td>Buttons Cloth Diaper Cover - One Size - 8 Colo...</td>\n",
       "      <td>Buttons vs. Best Bottoms reviewFirst thing I w...</td>\n",
       "      <td>5</td>\n",
       "      <td>Buttons vs Best Bottoms reviewFirst thing I wa...</td>\n",
       "      <td>{'buttons': 15, 'vs': 1, 'best': 19, 'bottoms'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135152</th>\n",
       "      <td>Maxi-Cosi Pria 70 with Tiny Fit Convertible Ca...</td>\n",
       "      <td>We've been using Britax for our boy (now 14 mo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Weve been using Britax for our boy now 14 mont...</td>\n",
       "      <td>{'weve': 2, 'been': 5, 'using': 1, 'britax': 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73725</th>\n",
       "      <td>Chicco Cortina Keyfit 30 Travel System, Miro</td>\n",
       "      <td>UPDATE 11/20/13 - I went ahead and used a tiny...</td>\n",
       "      <td>4</td>\n",
       "      <td>UPDATE 112013  I went ahead and used a tiny bi...</td>\n",
       "      <td>{'update': 2, '112013': 1, 'i': 54, 'went': 2,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>BabyPlus Prenatal Education System</td>\n",
       "      <td>I started wearing the Babyplus when I was 18 w...</td>\n",
       "      <td>5</td>\n",
       "      <td>I started wearing the Babyplus when I was 18 w...</td>\n",
       "      <td>{'i': 16, 'started': 2, 'wearing': 1, 'the': 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74899</th>\n",
       "      <td>Graco Blossom Highchair, Townsend</td>\n",
       "      <td>We love this highchair.  We have a 4 year old ...</td>\n",
       "      <td>5</td>\n",
       "      <td>We love this highchair  We have a 4 year old a...</td>\n",
       "      <td>{'we': 7, 'love': 5, 'this': 12, 'highchair': ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79357</th>\n",
       "      <td>WubbaNub Tabby Kitten</td>\n",
       "      <td>I first bought these when I again had to repla...</td>\n",
       "      <td>5</td>\n",
       "      <td>I first bought these when I again had to repla...</td>\n",
       "      <td>{'i': 17, 'first': 1, 'bought': 4, 'these': 5,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166409</th>\n",
       "      <td>Kiddy City N Move Stroller, Walnut</td>\n",
       "      <td>For starters, it's the only stroller my little...</td>\n",
       "      <td>4</td>\n",
       "      <td>For starters its the only stroller my little g...</td>\n",
       "      <td>{'for': 19, 'starters': 1, 'its': 9, 'the': 73...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134265</th>\n",
       "      <td>UPPAbaby Cruz Stroller, Denny</td>\n",
       "      <td>We bought this stroller after selling our belo...</td>\n",
       "      <td>5</td>\n",
       "      <td>We bought this stroller after selling our belo...</td>\n",
       "      <td>{'we': 8, 'bought': 1, 'this': 6, 'stroller': ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109574</th>\n",
       "      <td>phil&amp;amp;teds Smart Buggy Bassinet and Strolle...</td>\n",
       "      <td>My wife's 5', and I'm about 5'6\", our baby is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My wifes 5 and Im about 56 our baby is within ...</td>\n",
       "      <td>{'my': 3, 'wifes': 1, '5': 1, 'and': 29, 'im':...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>Kolcraft Contours Lite Stroller Plus with iPod...</td>\n",
       "      <td>After considering several lightweight stroller...</td>\n",
       "      <td>4</td>\n",
       "      <td>After considering several lightweight stroller...</td>\n",
       "      <td>{'after': 3, 'considering': 2, 'several': 2, '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180646</th>\n",
       "      <td>Mamas &amp;amp; Papas 2014 Urbo2 Stroller - Black</td>\n",
       "      <td>After much research I purchased an Urbo2. It's...</td>\n",
       "      <td>4</td>\n",
       "      <td>After much research I purchased an Urbo2 Its e...</td>\n",
       "      <td>{'after': 1, 'much': 3, 'research': 1, 'i': 17...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50591</th>\n",
       "      <td>BABYBJORN Travel Crib Light , Blue</td>\n",
       "      <td>BOTTOM LINE: I would buy this again in a heart...</td>\n",
       "      <td>5</td>\n",
       "      <td>BOTTOM LINE I would buy this again in a heartb...</td>\n",
       "      <td>{'bottom': 2, 'line': 1, 'i': 14, 'would': 4, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91485</th>\n",
       "      <td>Dream On Me / Mia Moda  Atmosferra Stroller, Nero</td>\n",
       "      <td>I love this stroller SO much! I am not afraid ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this stroller SO much I am not afraid t...</td>\n",
       "      <td>{'i': 15, 'love': 2, 'this': 6, 'stroller': 14...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111155</th>\n",
       "      <td>bumGenius One-Size Hook &amp;amp; Loop Closure Clo...</td>\n",
       "      <td>We did my son in cloth diapers from birth thro...</td>\n",
       "      <td>5</td>\n",
       "      <td>We did my son in cloth diapers from birth thro...</td>\n",
       "      <td>{'we': 1, 'did': 1, 'my': 12, 'son': 1, 'in': ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "59320        Evenflo Aura Select Travel System - Caroline   \n",
       "142686  Thirsties Duo Diaper Snap, Mud, Size One (6-18...   \n",
       "123632    Zooper 2011 Waltz Standard Stroller, Flax Brown   \n",
       "50735   Joovy Zoom 360 Swivel Wheel Jogging Stroller, ...   \n",
       "129722  Bumbleride 2011 Flite Lightweight Compact Trav...   \n",
       "100166  Infantino Wrap and Tie Baby Carrier, Black Blu...   \n",
       "168086  Buttons Cloth Diaper Cover - One Size - 8 Colo...   \n",
       "135152  Maxi-Cosi Pria 70 with Tiny Fit Convertible Ca...   \n",
       "73725        Chicco Cortina Keyfit 30 Travel System, Miro   \n",
       "57108                  BabyPlus Prenatal Education System   \n",
       "74899                   Graco Blossom Highchair, Townsend   \n",
       "79357                               WubbaNub Tabby Kitten   \n",
       "166409                 Kiddy City N Move Stroller, Walnut   \n",
       "134265                      UPPAbaby Cruz Stroller, Denny   \n",
       "109574  phil&amp;teds Smart Buggy Bassinet and Strolle...   \n",
       "41763   Kolcraft Contours Lite Stroller Plus with iPod...   \n",
       "180646      Mamas &amp; Papas 2014 Urbo2 Stroller - Black   \n",
       "50591                  BABYBJORN Travel Crib Light , Blue   \n",
       "91485   Dream On Me / Mia Moda  Atmosferra Stroller, Nero   \n",
       "111155  bumGenius One-Size Hook &amp; Loop Closure Clo...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "59320   I'm about to be a first-time mom, so I spent w...       5   \n",
       "142686  I will try to keep this short.  Have tried man...       5   \n",
       "123632  I did a TON of research before I purchased thi...       5   \n",
       "50735   The joovy zoom 360 was the perfect solution fo...       5   \n",
       "129722  This is a review of the 2012 Bumbleride Flite ...       5   \n",
       "100166  I bought this carrier when my daughter was abo...       5   \n",
       "168086  Buttons vs. Best Bottoms reviewFirst thing I w...       5   \n",
       "135152  We've been using Britax for our boy (now 14 mo...       5   \n",
       "73725   UPDATE 11/20/13 - I went ahead and used a tiny...       4   \n",
       "57108   I started wearing the Babyplus when I was 18 w...       5   \n",
       "74899   We love this highchair.  We have a 4 year old ...       5   \n",
       "79357   I first bought these when I again had to repla...       5   \n",
       "166409  For starters, it's the only stroller my little...       4   \n",
       "134265  We bought this stroller after selling our belo...       5   \n",
       "109574  My wife's 5', and I'm about 5'6\", our baby is ...       5   \n",
       "41763   After considering several lightweight stroller...       4   \n",
       "180646  After much research I purchased an Urbo2. It's...       4   \n",
       "50591   BOTTOM LINE: I would buy this again in a heart...       5   \n",
       "91485   I love this stroller SO much! I am not afraid ...       5   \n",
       "111155  We did my son in cloth diapers from birth thro...       5   \n",
       "\n",
       "                               review_without_punctuation  \\\n",
       "59320   Im about to be a firsttime mom so I spent week...   \n",
       "142686  I will try to keep this short  Have tried many...   \n",
       "123632  I did a TON of research before I purchased thi...   \n",
       "50735   The joovy zoom 360 was the perfect solution fo...   \n",
       "129722  This is a review of the 2012 Bumbleride Flite ...   \n",
       "100166  I bought this carrier when my daughter was abo...   \n",
       "168086  Buttons vs Best Bottoms reviewFirst thing I wa...   \n",
       "135152  Weve been using Britax for our boy now 14 mont...   \n",
       "73725   UPDATE 112013  I went ahead and used a tiny bi...   \n",
       "57108   I started wearing the Babyplus when I was 18 w...   \n",
       "74899   We love this highchair  We have a 4 year old a...   \n",
       "79357   I first bought these when I again had to repla...   \n",
       "166409  For starters its the only stroller my little g...   \n",
       "134265  We bought this stroller after selling our belo...   \n",
       "109574  My wifes 5 and Im about 56 our baby is within ...   \n",
       "41763   After considering several lightweight stroller...   \n",
       "180646  After much research I purchased an Urbo2 Its e...   \n",
       "50591   BOTTOM LINE I would buy this again in a heartb...   \n",
       "91485   I love this stroller SO much I am not afraid t...   \n",
       "111155  We did my son in cloth diapers from birth thro...   \n",
       "\n",
       "                                               word_count  sentiment  \\\n",
       "59320   {'im': 2, 'about': 3, 'to': 14, 'be': 4, 'a': ...          1   \n",
       "142686  {'i': 18, 'will': 2, 'try': 1, 'to': 15, 'keep...          1   \n",
       "123632  {'i': 20, 'did': 1, 'a': 52, 'ton': 1, 'of': 3...          1   \n",
       "50735   {'the': 61, 'joovy': 1, 'zoom': 1, '360': 1, '...          1   \n",
       "129722  {'this': 12, 'is': 23, 'a': 38, 'review': 2, '...          1   \n",
       "100166  {'i': 28, 'bought': 1, 'this': 6, 'carrier': 7...          1   \n",
       "168086  {'buttons': 15, 'vs': 1, 'best': 19, 'bottoms'...          1   \n",
       "135152  {'weve': 2, 'been': 5, 'using': 1, 'britax': 5...          1   \n",
       "73725   {'update': 2, '112013': 1, 'i': 54, 'went': 2,...          1   \n",
       "57108   {'i': 16, 'started': 2, 'wearing': 1, 'the': 1...          1   \n",
       "74899   {'we': 7, 'love': 5, 'this': 12, 'highchair': ...          1   \n",
       "79357   {'i': 17, 'first': 1, 'bought': 4, 'these': 5,...          1   \n",
       "166409  {'for': 19, 'starters': 1, 'its': 9, 'the': 73...          1   \n",
       "134265  {'we': 8, 'bought': 1, 'this': 6, 'stroller': ...          1   \n",
       "109574  {'my': 3, 'wifes': 1, '5': 1, 'and': 29, 'im':...          1   \n",
       "41763   {'after': 3, 'considering': 2, 'several': 2, '...          1   \n",
       "180646  {'after': 1, 'much': 3, 'research': 1, 'i': 17...          1   \n",
       "50591   {'bottom': 2, 'line': 1, 'i': 14, 'would': 4, ...          1   \n",
       "91485   {'i': 15, 'love': 2, 'this': 6, 'stroller': 14...          1   \n",
       "111155  {'we': 1, 'did': 1, 'my': 12, 'son': 1, 'in': ...          1   \n",
       "\n",
       "        predicted_probab  \n",
       "59320                1.0  \n",
       "142686               1.0  \n",
       "123632               1.0  \n",
       "50735                1.0  \n",
       "129722               1.0  \n",
       "100166               1.0  \n",
       "168086               1.0  \n",
       "135152               1.0  \n",
       "73725                1.0  \n",
       "57108                1.0  \n",
       "74899                1.0  \n",
       "79357                1.0  \n",
       "166409               1.0  \n",
       "134265               1.0  \n",
       "109574               1.0  \n",
       "41763                1.0  \n",
       "180646               1.0  \n",
       "50591                1.0  \n",
       "91485                1.0  \n",
       "111155               1.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted_probab = sentiment_model.predict_proba(test_X)\n",
    "#tpp = sorted(test_predicted_probab[:, 1], reverse=True)\n",
    "#print(tpp)\n",
    "test_data[\"predicted_probab\"] = test_predicted_probab[:, 1]\n",
    "sorted_test_data = test_data.sort_values(by=['predicted_probab'], ascending=False)\n",
    "sorted_test_data.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most positive reviews? [multiple choice]\n",
    "\n",
    "\n",
    "Now, let us repeat this exercise to find the \"most negative reviews.\" Use the prediction probabilities to find the  20 reviews in the **test_data** with the **lowest probability** of being classified as a **positive review**. Repeat the same steps above but make sure you **sort in the opposite order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_without_punctuation</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147902</th>\n",
       "      <td>Graco Pack 'n Play Playard - Dempsey</td>\n",
       "      <td>My disappointment with this product prompted m...</td>\n",
       "      <td>1</td>\n",
       "      <td>My disappointment with this product prompted m...</td>\n",
       "      <td>{'my': 5, 'disappointment': 2, 'with': 11, 'th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.519005e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175191</th>\n",
       "      <td>Zooper Twist Escape Stroller, Summer Day</td>\n",
       "      <td>I had to return this stroller for three reason...</td>\n",
       "      <td>1</td>\n",
       "      <td>I had to return this stroller for three reason...</td>\n",
       "      <td>{'i': 37, 'had': 4, 'to': 21, 'return': 2, 'th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.536451e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89902</th>\n",
       "      <td>Peg-Perego Aria Twin Stroller, Java</td>\n",
       "      <td>I am so incredibly disappointed with the strol...</td>\n",
       "      <td>1</td>\n",
       "      <td>I am so incredibly disappointed with the strol...</td>\n",
       "      <td>{'i': 16, 'am': 1, 'so': 3, 'incredibly': 1, '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.743083e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>{'i': 18, 'thought': 1, 'it': 8, 'sounded': 1,...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.919969e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57234</th>\n",
       "      <td>Dream On Me Bassinet, Blue</td>\n",
       "      <td>My husband and I are VERY disappointed and sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband and I are VERY disappointed and sho...</td>\n",
       "      <td>{'my': 3, 'husband': 2, 'and': 14, 'i': 12, 'a...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.031679e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>{'this': 12, 'is': 15, 'my': 6, 'second': 3, '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.477205e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>{'i': 26, 'will': 4, 'try': 2, 'to': 29, 'writ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.387718e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27310</th>\n",
       "      <td>Evenflo Expressions Plus High Chair - 3's Company</td>\n",
       "      <td>PLEASE HEED THE OTHER REVIEWERS WARNINGS ON TH...</td>\n",
       "      <td>1</td>\n",
       "      <td>PLEASE HEED THE OTHER REVIEWERS WARNINGS ON TH...</td>\n",
       "      <td>{'please': 2, 'heed': 1, 'the': 18, 'other': 2...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.586368e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145109</th>\n",
       "      <td>Withings Smart Baby Monitor, White</td>\n",
       "      <td>Ok, the good.  During the day, the quality of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ok the good  During the day the quality of the...</td>\n",
       "      <td>{'ok': 1, 'the': 31, 'good': 1, 'during': 1, '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.937239e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>{'do': 1, 'not': 2, 'buy': 1, 'this': 6, 'baby...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.550801e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123506</th>\n",
       "      <td>Peg-Perego Vela Easy Drive Stroller, Geranium</td>\n",
       "      <td>DO not buy this stroller, it is horrible and a...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO not buy this stroller it is horrible and a ...</td>\n",
       "      <td>{'do': 2, 'not': 7, 'buy': 1, 'this': 3, 'stro...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.917712e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13742</th>\n",
       "      <td>Medela Pump &amp;amp; Save Breastmilk Bags - 50 pa...</td>\n",
       "      <td>Let me start by saying that, after three kids,...</td>\n",
       "      <td>1</td>\n",
       "      <td>Let me start by saying that after three kids I...</td>\n",
       "      <td>{'let': 1, 'me': 4, 'start': 1, 'by': 1, 'sayi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.784116e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>Medela Pump &amp;amp; Save Breastmilk Bags - 50 pa...</td>\n",
       "      <td>I must agree with the negative reviews of this...</td>\n",
       "      <td>1</td>\n",
       "      <td>I must agree with the negative reviews of this...</td>\n",
       "      <td>{'i': 6, 'must': 1, 'agree': 1, 'with': 3, 'th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.523604e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111334</th>\n",
       "      <td>Regalo Top of Stair Gate, White</td>\n",
       "      <td>If you don't want your child falling down the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>If you dont want your child falling down the s...</td>\n",
       "      <td>{'if': 6, 'you': 8, 'dont': 4, 'want': 2, 'you...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.430705e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127472</th>\n",
       "      <td>Argington Organic Bam Bam Crib Complete, Ebony</td>\n",
       "      <td>Please do not buy this crib. I so wanted to lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Please do not buy this crib I so wanted to lov...</td>\n",
       "      <td>{'please': 1, 'do': 1, 'not': 3, 'buy': 1, 'th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.438674e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127820</th>\n",
       "      <td>Mountain Buggy Duet Double Buggy Stroller, Bla...</td>\n",
       "      <td>Being a mom, I'm a big proponent of reviews by...</td>\n",
       "      <td>2</td>\n",
       "      <td>Being a mom Im a big proponent of reviews by o...</td>\n",
       "      <td>{'being': 2, 'a': 45, 'mom': 1, 'im': 5, 'big'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.038694e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23989</th>\n",
       "      <td>American Baby Company Waterproof Quilted Cotto...</td>\n",
       "      <td>I HAVE AN ISSUE WITH THIS ORDER! On this same ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I HAVE AN ISSUE WITH THIS ORDER On this same d...</td>\n",
       "      <td>{'i': 20, 'have': 4, 'an': 1, 'issue': 1, 'wit...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.245261e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174157</th>\n",
       "      <td>Kidz Delight Smithsonian Kids Space Tablet</td>\n",
       "      <td>First, the machine has three modes: Discovery,...</td>\n",
       "      <td>2</td>\n",
       "      <td>First the machine has three modes Discovery Ex...</td>\n",
       "      <td>{'first': 3, 'the': 65, 'machine': 1, 'has': 1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.886387e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>{'this': 3, 'item': 1, 'is': 2, 'junk': 2, 'i'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.117012e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162337</th>\n",
       "      <td>Summer Infant Connect Internet Camera System</td>\n",
       "      <td>You've already heard from other reviews - this...</td>\n",
       "      <td>1</td>\n",
       "      <td>Youve already heard from other reviews  this i...</td>\n",
       "      <td>{'youve': 1, 'already': 1, 'heard': 1, 'from':...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.188480e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "147902               Graco Pack 'n Play Playard - Dempsey   \n",
       "175191           Zooper Twist Escape Stroller, Summer Day   \n",
       "89902                 Peg-Perego Aria Twin Stroller, Java   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "57234                          Dream On Me Bassinet, Blue   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "27310   Evenflo Expressions Plus High Chair - 3's Company   \n",
       "145109                 Withings Smart Baby Monitor, White   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "123506      Peg-Perego Vela Easy Drive Stroller, Geranium   \n",
       "13742   Medela Pump &amp; Save Breastmilk Bags - 50 pa...   \n",
       "13793   Medela Pump &amp; Save Breastmilk Bags - 50 pa...   \n",
       "111334                    Regalo Top of Stair Gate, White   \n",
       "127472     Argington Organic Bam Bam Crib Complete, Ebony   \n",
       "127820  Mountain Buggy Duet Double Buggy Stroller, Bla...   \n",
       "23989   American Baby Company Waterproof Quilted Cotto...   \n",
       "174157         Kidz Delight Smithsonian Kids Space Tablet   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "162337       Summer Infant Connect Internet Camera System   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "147902  My disappointment with this product prompted m...       1   \n",
       "175191  I had to return this stroller for three reason...       1   \n",
       "89902   I am so incredibly disappointed with the strol...       1   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "57234   My husband and I are VERY disappointed and sho...       1   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "27310   PLEASE HEED THE OTHER REVIEWERS WARNINGS ON TH...       1   \n",
       "145109  Ok, the good.  During the day, the quality of ...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "123506  DO not buy this stroller, it is horrible and a...       1   \n",
       "13742   Let me start by saying that, after three kids,...       1   \n",
       "13793   I must agree with the negative reviews of this...       1   \n",
       "111334  If you don't want your child falling down the ...       1   \n",
       "127472  Please do not buy this crib. I so wanted to lo...       1   \n",
       "127820  Being a mom, I'm a big proponent of reviews by...       2   \n",
       "23989   I HAVE AN ISSUE WITH THIS ORDER! On this same ...       1   \n",
       "174157  First, the machine has three modes: Discovery,...       2   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "162337  You've already heard from other reviews - this...       1   \n",
       "\n",
       "                               review_without_punctuation  \\\n",
       "147902  My disappointment with this product prompted m...   \n",
       "175191  I had to return this stroller for three reason...   \n",
       "89902   I am so incredibly disappointed with the strol...   \n",
       "77072   I thought it sounded great to have different t...   \n",
       "57234   My husband and I are VERY disappointed and sho...   \n",
       "155287  This is my second video monitoring system the ...   \n",
       "48694   I will try to write an objective review of the...   \n",
       "27310   PLEASE HEED THE OTHER REVIEWERS WARNINGS ON TH...   \n",
       "145109  Ok the good  During the day the quality of the...   \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...   \n",
       "123506  DO not buy this stroller it is horrible and a ...   \n",
       "13742   Let me start by saying that after three kids I...   \n",
       "13793   I must agree with the negative reviews of this...   \n",
       "111334  If you dont want your child falling down the s...   \n",
       "127472  Please do not buy this crib I so wanted to lov...   \n",
       "127820  Being a mom Im a big proponent of reviews by o...   \n",
       "23989   I HAVE AN ISSUE WITH THIS ORDER On this same d...   \n",
       "174157  First the machine has three modes Discovery Ex...   \n",
       "1116    This item is junk  I originally chose it becau...   \n",
       "162337  Youve already heard from other reviews  this i...   \n",
       "\n",
       "                                               word_count  sentiment  \\\n",
       "147902  {'my': 5, 'disappointment': 2, 'with': 11, 'th...         -1   \n",
       "175191  {'i': 37, 'had': 4, 'to': 21, 'return': 2, 'th...         -1   \n",
       "89902   {'i': 16, 'am': 1, 'so': 3, 'incredibly': 1, '...         -1   \n",
       "77072   {'i': 18, 'thought': 1, 'it': 8, 'sounded': 1,...         -1   \n",
       "57234   {'my': 3, 'husband': 2, 'and': 14, 'i': 12, 'a...         -1   \n",
       "155287  {'this': 12, 'is': 15, 'my': 6, 'second': 3, '...         -1   \n",
       "48694   {'i': 26, 'will': 4, 'try': 2, 'to': 29, 'writ...         -1   \n",
       "27310   {'please': 2, 'heed': 1, 'the': 18, 'other': 2...         -1   \n",
       "145109  {'ok': 1, 'the': 31, 'good': 1, 'during': 1, '...         -1   \n",
       "113995  {'do': 1, 'not': 2, 'buy': 1, 'this': 6, 'baby...         -1   \n",
       "123506  {'do': 2, 'not': 7, 'buy': 1, 'this': 3, 'stro...         -1   \n",
       "13742   {'let': 1, 'me': 4, 'start': 1, 'by': 1, 'sayi...         -1   \n",
       "13793   {'i': 6, 'must': 1, 'agree': 1, 'with': 3, 'th...         -1   \n",
       "111334  {'if': 6, 'you': 8, 'dont': 4, 'want': 2, 'you...         -1   \n",
       "127472  {'please': 1, 'do': 1, 'not': 3, 'buy': 1, 'th...         -1   \n",
       "127820  {'being': 2, 'a': 45, 'mom': 1, 'im': 5, 'big'...         -1   \n",
       "23989   {'i': 20, 'have': 4, 'an': 1, 'issue': 1, 'wit...         -1   \n",
       "174157  {'first': 3, 'the': 65, 'machine': 1, 'has': 1...         -1   \n",
       "1116    {'this': 3, 'item': 1, 'is': 2, 'junk': 2, 'i'...         -1   \n",
       "162337  {'youve': 1, 'already': 1, 'heard': 1, 'from':...         -1   \n",
       "\n",
       "        predicted_probab  \n",
       "147902      1.519005e-20  \n",
       "175191      1.536451e-18  \n",
       "89902       4.743083e-16  \n",
       "77072       2.919969e-14  \n",
       "57234       5.031679e-14  \n",
       "155287      1.477205e-13  \n",
       "48694       4.387718e-13  \n",
       "27310       2.586368e-12  \n",
       "145109      4.937239e-12  \n",
       "113995      1.550801e-11  \n",
       "123506      1.917712e-11  \n",
       "13742       5.784116e-11  \n",
       "13793       1.523604e-10  \n",
       "111334      2.430705e-10  \n",
       "127472      2.438674e-10  \n",
       "127820      4.038694e-10  \n",
       "23989       5.245261e-10  \n",
       "174157      5.886387e-10  \n",
       "1116        9.117012e-10  \n",
       "162337      1.188480e-09  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortasc_test_data = test_data.sort_values(by=['predicted_probab'])\n",
    "sortasc_test_data.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    predicted_labels = model.predict(data)\n",
    "    # Compute the number of correctly classified examples\n",
    "    is_correct = predicted_labels == true_labels\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    accuracy = len(predicted_labels[is_correct]) / len(is_correct)    \n",
    "    return round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76).\n",
    "\n",
    "**Quiz Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The CountVectorizer class has a parameter that lets you limit the choice of words when building word count vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_subset = CountVectorizer(vocabulary=significant_words, token_pattern=r'\\b\\w+\\b')\n",
    "vectorizer_subset.fit(train_data['review_without_punctuation'])\n",
    "train_subsetX = vectorizer_subset.transform(train_data['review_without_punctuation'])\n",
    "test_subsetX = vectorizer_subset.transform(test_data['review_without_punctuation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a logistic regression classifier with train_subsetX as features and sentiment as the target. Call this model simple_model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = LogisticRegression().fit(train_subsetX, train_y)\n",
    "simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_subsetX, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_word_coeff = list(zip(significant_words, simple_model.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loves 1.7002126297879914\n",
      "perfect 1.5211189888958407\n",
      "love 1.3565592559668063\n",
      "easy 1.1910888644843223\n",
      "great 0.9304893797198319\n",
      "little 0.5016435568952592\n",
      "well 0.4963916116267885\n",
      "able 0.19415647830494415\n",
      "car 0.07437784605925846\n",
      "old 0.07200503919828553\n",
      "less -0.2072725288874614\n",
      "product -0.31254568418681616\n",
      "would -0.33976004912745755\n",
      "even -0.49098622834583944\n",
      "work -0.6377412762768394\n",
      "money -0.9390450134203616\n",
      "broke -1.6674849670557026\n",
      "waste -2.0078030433921525\n",
      "return -2.0778697599619242\n",
      "disappointed -2.3892080334806995\n"
     ]
    }
   ],
   "source": [
    "simple_sorted_coeff = sorted(sig_word_coeff, key=lambda item:item[1], reverse=True)\n",
    "x = [print(word, coeff) for (word, coeff) in simple_sorted_coeff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of coefficients: 20\n",
      "No of +ve coefficients: 10\n",
      "No of -ve coefficients: 10\n"
     ]
    }
   ],
   "source": [
    "print_model_coeff(simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients of positive significant words in sentiment model are: \n",
      "little 0.15164453105926956\n",
      "loves 0.011549433621536582\n",
      "great 0.047411474236942606\n",
      "able -1.3615587537135288e-05\n",
      "love -0.5151738423059505\n",
      "well 0.0007458305098735024\n",
      "easy -0.32309924542536894\n",
      "old -4.956880375287803e-06\n",
      "perfect 0.011841798351930598\n",
      "car 0.4449835489327556\n"
     ]
    }
   ],
   "source": [
    "positive_significant_words = [word for (word, coeff) in simple_sorted_coeff if coeff > 0]\n",
    "all_words_coeff = list(zip(vectorizer.vocabulary_.keys(), sentiment_model.coef_[0]))\n",
    "print('The coefficients of positive significant words in sentiment model are: ')\n",
    "all_positive_words = [print(word, coeff) for (word, coeff) in all_words_coeff if word in positive_significant_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, train_subsetX, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_subsetX, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112182\n",
      "21219\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (train_data['sentiment'] == +1).sum()\n",
    "num_negative = (train_data['sentiment'] == -1).sum()\n",
    "print(num_positive)\n",
    "print(num_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28077 5274\n",
      "majority class classifier accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "num_test_positive = (test_y == +1).sum()\n",
    "num_test_negative = (test_y == -1).sum()\n",
    "print(num_test_positive, num_test_negative)\n",
    "majority_class_classifier_accuracy = round(num_test_positive / len(test_y), 2)\n",
    "print('majority class classifier accuracy: {}'.format(majority_class_classifier_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
