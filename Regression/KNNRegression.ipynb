{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "\n",
    "Find the k-nearest neighbors of a given query input Predict the output for the query input using the k-nearest neighbors Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# dictionary with dataset column names and their corresponding data types\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, \n",
    "              'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, \n",
    "              'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, \n",
    "              'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train, test and validate datasets in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of training dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257         1340.0   \n",
       "1      1951          1991    98125  47.7210 -122.319         1690.0   \n",
       "2      1933             0    98028  47.7379 -122.233         2720.0   \n",
       "3      1965             0    98136  47.5208 -122.393         1360.0   \n",
       "4      1987             0    98074  47.6168 -122.045         1800.0   \n",
       "\n",
       "   sqft_lot15  \n",
       "0      5650.0  \n",
       "1      7639.0  \n",
       "2      8062.0  \n",
       "3      5000.0  \n",
       "4      7503.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change directory to the location where the data for the notebook is located\n",
    "os.chdir('D:\\Anupam_Technical\\Code\\ML\\DS_ML_Projects\\Regression\\data\\knn')\n",
    "train = pd.read_csv('kc_house_data_small_train.csv', dtype = dtype_dict)\n",
    "print('Top 5 rows of training dataset')\n",
    "display(train.head())\n",
    "test = pd.read_csv('kc_house_data_small_test.csv', dtype = dtype_dict)\n",
    "validate = pd.read_csv('kc_house_data_validation.csv', dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts input and output features from a dataframe and return a tuple of input features numpy 2d array and output feature vector (numpy 1d array). Note that we need to add a column vector of all ones as the first column of the input feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column vector of all ones to the begining of a feature matrix\n",
    "def add_one_vector(X):\n",
    "    one_vector = np.ones(len(X)).reshape(len(X), 1)\n",
    "    return np.concatenate((one_vector, X), axis=1)\n",
    "\n",
    "\n",
    "def extract_features(df, datatype_dict):\n",
    "    \"\"\"\n",
    "    Extract input and output features from a dataframe and return a tuple of input features matrix and output \n",
    "    feature vector\n",
    "    :param df: dataframe\n",
    "    :param datatype_dict: dictionary with dataset column names and their corresponding data types\n",
    "    :return: a tuple of input features matrix and output feature vector\n",
    "    \"\"\"    \n",
    "    # remove the columns that are not numeric i.e. int, floats etc.\n",
    "    # train.dtypes gives a pandas with index as column names and value as column data types. We filter this\n",
    "    # series to remove columns of type object\n",
    "    numeric_cols = pd.Series(train.dtypes).where(lambda col_dtype: col_dtype != 'object').dropna()\n",
    "    feature_names = list(numeric_cols.keys().values)\n",
    "    # price is the output variable\n",
    "    feature_names.remove('price')\n",
    "    # extract the input features from the dataframe as a numpy 2d array\n",
    "    input_features = add_one_vector(df[feature_names].values)\n",
    "    output_variable = df.loc[:, 'price'].values\n",
    "    return input_features, output_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_features, train_output = extract_features(train, dtype_dict)\n",
    "cv_input_features, cv_output = extract_features(validate, dtype_dict)\n",
    "test_input_features, test_output = extract_features(test, dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the ‘sqft_living’ feature (typically on the order of thousands) would exert a much larger influence on distance than the ‘bedrooms’ feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(input_features):\n",
    "    norm = np.sqrt(np.sum(input_features**2, axis=0))\n",
    "    normalized_features = input_features / norm\n",
    "    return normalized_features, norm\n",
    "\n",
    "norm_train_input_features, train_norm = normalize_features(train_input_features)\n",
    "norm_cv_input_features = cv_input_features / train_norm\n",
    "norm_test_input_features = test_input_features / train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's just explore computing the “distance” between two given houses. We will take our query house to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1. Similarly, print the 10th row (index 9) of the training feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059\n",
      "  0.          0.05102365  0.0116321   0.01564352  0.01362084  0.02481682\n",
      "  0.01350306  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n",
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346251  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print(norm_test_input_features[0])\n",
    "print(norm_train_input_features[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Euclidean distance between the query house and the 10th house of the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05972359371398078"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((norm_train_input_features[9] - norm_test_input_features[0])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to do nearest neighbor regression, we need to compute the distance between our query house and all houses in the training set.\n",
    "\n",
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (features_test[0]) to the first 10 houses of the training set (norm_train_input_features[0:10]) and then search for the nearest neighbor within this small set of houses. Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set.\n",
    "\n",
    "Quiz Question: Among the first 10 training houses, which house is the closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.06027470916295592, 1: 0.08546881147643746, 2: 0.06149946435279315, 3: 0.05340273979294363, 4: 0.05844484060170442, 5: 0.059879215098128345, 6: 0.05463140496775461, 7: 0.055431083236146074, 8: 0.052383627840220305, 9: 0.05972359371398078}\n"
     ]
    }
   ],
   "source": [
    "distance = {}\n",
    "for i in range(10):\n",
    "    distance[i] = np.sqrt(np.sum((norm_train_input_features[i] - norm_test_input_features[0])**2))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 0.052383627840220305), (3, 0.05340273979294363), (6, 0.05463140496775461), (7, 0.055431083236146074), (4, 0.05844484060170442), (9, 0.05972359371398078), (5, 0.059879215098128345), (0, 0.06027470916295592), (2, 0.06149946435279315), (1, 0.08546881147643746)]\n"
     ]
    }
   ],
   "source": [
    "distance_sorted = sorted(distance.items(), key=lambda item: item[1])\n",
    "print(distance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform one nearest neighbour regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the element-wise differences, it is not too hard to compute the Euclidean distances between our query house and all of the training houses. First, write a single-line expression to define a variable ‘diff’ such that ‘diff[i]’ gives the element-wise difference between the features of the query house and the i-th training house.\n",
    "\n",
    "To test your code, print diff[-1].sum(), which should be -0.0934339605842."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09343399874654643"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = norm_train_input_features[:] - norm_test_input_features[0]\n",
    "diff[-1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in computing the Euclidean distances is to take these feature-by-feature differences in ‘diff’, square each, and take the sum over feature indices. That is, compute the sum of squared feature differences for each training house (row in ‘diff’).\n",
    "\n",
    "By default, ‘np.sum’ sums up everything in the matrix and returns a single number. To instead sum only over a row or column, we need to specifiy the ‘axis’ parameter described in the np.sum documentation. In particular, ‘axis=1’ computes the sum across each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(training_examples, query_house):\n",
    "    \"\"\"\n",
    "    Vectorized implementation of calculating the distance of a query house from each of the training examples\n",
    "    :param training_examples: a matrix or numpy 2d array consisting of training data (input features)\n",
    "    :param query_house: the query house\n",
    "    :return: numpy 2d array whose first column is the training row index and second column is the distance from\n",
    "    the query house\n",
    "    \"\"\"\n",
    "    # subtract the query house row from each training example row\n",
    "    diff_matrix = training_examples - query_house\n",
    "    # now for each row in the matrix (which corresponds to each training example), calculate the sum of\n",
    "    # squares of feature values ( this is done by using axis = 1 in the 2d array )\n",
    "    distance = np.sqrt(np.sum(diff_matrix**2, axis=1))\n",
    "    index = np.arange(0, len(distance))    \n",
    "    return np.concatenate((index.reshape(-1, 1), distance.reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the distance of the third test example from each of the training examples. Then find out which training example is the closest to the query house. Note that the expected value is row index 382 has the min. distance of 0.0028604955575117085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 0.0028604955575117085\n"
     ]
    }
   ],
   "source": [
    "rowindex_distance = compute_distance(norm_train_input_features[:], norm_test_input_features[2])\n",
    "\n",
    "def get_min_distance_row_index(rowindex_distance):\n",
    "    rowindex = rowindex_distance[:, 0]\n",
    "    distance = rowindex_distance[:, 1]\n",
    "    min_distance = np.amin(distance)\n",
    "    min_distance_index = np.where(distance == min_distance)\n",
    "    return rowindex[min_distance_index], min_distance\n",
    "\n",
    "min_row_index, min_distance = get_min_distance_row_index(rowindex_distance)\n",
    "print(int(min_row_index[0]), min_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the predicted value of the query house (third test example) based on 1-nearest neighbor regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249000.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the query house ( i.e. the third test example) is closest to the 382nd training example, hence the predicted \n",
    "# value of the query house will be same as the price of the 382nd training example\n",
    "train_output[382]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above, implement a function that takes in\n",
    "\n",
    "the value of k; the feature matrix for the instances; and the feature of the query and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(k, training_examples, query_house):\n",
    "    rownumber_distance = compute_distance(training_examples, query_house)\n",
    "    # sort the 2d array on the index column in ascending order\n",
    "    # You can call .argsort() on the column you want to sort, and it will give you an array of row indices \n",
    "    # that sort that particular column which you can pass as an index to your original array.\n",
    "    rownumber_distance_sorted = rownumber_distance[rownumber_distance[:, 1].argsort()]\n",
    "    return rownumber_distance_sorted[0:k, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the query house to be third house of the test set (norm_test_input_features[2]). What are the indices of the 4 training houses closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 382 1149 4087 3142]\n"
     ]
    }
   ],
   "source": [
    "knn_rowindex_distance = k_nearest_neighbours(4, norm_train_input_features[:], norm_test_input_features[2])\n",
    "print(knn_rowindex_distance[:, 0].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. For simplicity, take the average of the prices of the k nearest neighbors in the training set. The function should have the following parameters:\n",
    "\n",
    "<ul>\n",
    "    <li>the value of k;</li>\n",
    "    <li>the feature matrix for the instances;</li>\n",
    "    <li>the output values (prices) of the instances; and</li>\n",
    "    <li>the feature of the query, whose price we’re predicting.</li>\n",
    "</ul>\n",
    "The function should return a predicted value of the query house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_house_price_custom(k, train_input_features, train_output, query_house):\n",
    "    k_rowindex_distance = k_nearest_neighbours(k, train_input_features, query_house)\n",
    "    # get the rowindex of the k nearest neighbours and get their corresponding prices\n",
    "    k_rowindex = k_rowindex_distance[:, 0].astype(int)\n",
    "    # get the mean of the k nearest house prices, this is the predicted price of the query house\n",
    "    return np.mean(train_output[k_rowindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for the first 10 houses in the test set, using k=10. What is the index of the house in this query set that has the lowest predicted value? What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 350032.0), (3, 430200.0), (1, 431860.0), (9, 457235.0), (2, 460595.0), (8, 484000.0), (7, 512800.7), (5, 667420.0), (4, 766750.0), (0, 881300.0)]\n",
      "\n",
      "House index in test set of 10 houses with lowest predicted price: 6\n"
     ]
    }
   ],
   "source": [
    "query_house_predicted_price = []\n",
    "\n",
    "for query_house_index in range(10):\n",
    "    query_house = norm_test_input_features[query_house_index]\n",
    "    predicted_price = predict_house_price_custom(10, norm_train_input_features, train_output, query_house)\n",
    "    query_house_predicted_price.append((query_house_index, predicted_price))\n",
    "\n",
    "# sort on the basis of predicted prices in ascending order    \n",
    "sorted_query_house_predicted_price = sorted(query_house_predicted_price, key=lambda item:item[1])\n",
    "print(sorted_query_house_predicted_price)\n",
    "print('\\nHouse index in test set of 10 houses with lowest predicted price: {}'\n",
    "      .format(sorted_query_house_predicted_price[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "For k in [1, 2, … 15]:\n",
    "\n",
    "Make predictions for the VALIDATION data using the k-nearest neighbors from the TRAINING data. Compute the RSS on VALIDATION data Report which k produced the lowest RSS on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 --> rss: 105453830251561.0\n",
      "k: 2 --> rss: 83445073504025.5\n",
      "k: 3 --> rss: 72692096019202.56\n",
      "k: 4 --> rss: 71946721652091.69\n",
      "k: 5 --> rss: 69846517419718.6\n",
      "k: 6 --> rss: 68899544353180.836\n",
      "k: 7 --> rss: 68341973450051.09\n",
      "k: 8 --> rss: 67361678735491.5\n",
      "k: 9 --> rss: 68372727958976.09\n",
      "k: 10 --> rss: 69335048668556.74\n",
      "k: 11 --> rss: 69523855215598.83\n",
      "k: 12 --> rss: 69049969587246.17\n",
      "k: 13 --> rss: 70011254508263.69\n",
      "k: 14 --> rss: 70908698869034.34\n",
      "k: 15 --> rss: 71106928385945.16\n",
      "\n",
      " The value of k that minimizes RSS on validation data is: 8\n"
     ]
    }
   ],
   "source": [
    "def get_optimized_kvalue(list_kvalues, predict_house_price):\n",
    "    k_rss = []\n",
    "    for k in list_kvalues:    \n",
    "        queryhouseindex_predictedprice_actualprice = []\n",
    "        for query_house_index in range(len(norm_cv_input_features)):\n",
    "            query_house = norm_cv_input_features[query_house_index]\n",
    "            actual_price = cv_output[query_house_index]\n",
    "            predicted_price = predict_house_price(k, norm_train_input_features, train_output, query_house)\n",
    "            queryhouseindex_predictedprice_actualprice.append([query_house_index, predicted_price, actual_price])\n",
    "        queryhouseindex_predictedprice_actualprice = np.array(queryhouseindex_predictedprice_actualprice)            \n",
    "        # now calculate the residual sum of squares ( (predicted value - actual value)**2 ) over the entire validation set\n",
    "        price_diff = (queryhouseindex_predictedprice_actualprice[:, 1] - queryhouseindex_predictedprice_actualprice[:, 2])**2\n",
    "        rss = np.sum(price_diff)\n",
    "        k_rss.append((k, rss))   \n",
    "        print('k: {} --> rss: {}'.format(k, rss))\n",
    "    sorted_k_rss = sorted(k_rss, key=lambda item:item[1])    \n",
    "    return sorted_k_rss[0][0]\n",
    "\n",
    "optimized_k = get_optimized_kvalue(np.arange(15)+1, predict_house_price_custom)\n",
    "print('\\n The value of k that minimizes RSS on validation data is: {}'.format(optimized_k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 --> rss: [1.05451198e+14]\n",
      "k: 2 --> rss: [8.3482811e+13]\n",
      "k: 3 --> rss: [7.26620105e+13]\n",
      "k: 4 --> rss: [7.16405256e+13]\n",
      "k: 5 --> rss: [6.95642264e+13]\n",
      "k: 6 --> rss: [6.8640568e+13]\n",
      "k: 7 --> rss: [6.7961639e+13]\n",
      "k: 8 --> rss: [6.69584338e+13]\n",
      "k: 9 --> rss: [6.76112457e+13]\n",
      "k: 10 --> rss: [6.79035784e+13]\n",
      "k: 11 --> rss: [6.79588549e+13]\n",
      "k: 12 --> rss: [6.77070525e+13]\n",
      "k: 13 --> rss: [6.84091455e+13]\n",
      "k: 14 --> rss: [6.90942193e+13]\n",
      "k: 15 --> rss: [6.9224199e+13]\n",
      "\n",
      " The value of k (using scikit nearest neighbors) that minimizes RSS on validation data is: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def predict_house_price_scikit(k, train_input_features, train_output, query_house):\n",
    "    k10_regressor = KNeighborsRegressor(n_neighbors = k, weights='distance')\n",
    "    k10_regressor.fit(train_input_features, train_output)    \n",
    "    return k10_regressor.predict(query_house.reshape(1, -1))\n",
    "\n",
    "predict_house_price_scikit(4, norm_train_input_features, train_output, norm_test_input_features[2])\n",
    "optimized_k_scikit = get_optimized_kvalue(np.arange(15)+1, predict_house_price_scikit)\n",
    "print('\\n The value of k (using scikit nearest neighbors) that minimizes RSS on validation data is: {}'\n",
    "      .format(optimized_k_scikit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
